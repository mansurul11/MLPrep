Logistic Regression:
1. linear model (output is the probability of an instance being in a class)
2. sigmoid(wTx+b)=y
3. log loss: sum over all training points -y*log(y) - (1-y)*log(1-y) [cross entropy as well]
4. regularization through: 
  - l2 (ridge) square sum over W's 
    - has derivative and convex
    - set W's to small values
  - l1 (lasso) sum over W's
    - no derivative, concave
    - set W's to zero indicates selection of feature
5. Advantages:
    - computationally faster
    - It makes no assumptions about distributions of classes in feature space.
    - easy to extend for multi class setting
    - interpretable
6. Disadvantages:
    - if not enough data but large number feature cause overfitting
    - assumption of linearity between features and label is not always true
    - always generate linear boundery
    - Cannot handle multi-colinearity
SVM:
1. Support vector machines that aims to separate classes by maximum width margin.
2. Output +1 and -1 as prediction
3. formulated as an optimization problem to minimze 1/|w|^2 here w is the distance between wTx+b=0 and wTx+b=+1 and wTx+b=-1
4. The data points on the line wTx+b=+1 and wTx+b=-1 are called support vectors
5. To handle nonlinera data, kernel is applicable to the data points to transform the to higher dimension where the data points become linearly separable.
6. polynomial, radial-basis are the kernel and RBF is the most popular.
7. To train, we can use hinge loss (max (0, 1-y*y^) y^ = wTx+b) - loss if 0 if y and y^ has the same sign (+1,+1) OR (-1,-1) and 2 is they are opposite)
8. final loss function is : sum over all data points:  max (0, 1-y*y^) + C*epsilon, here epsilon is the noise where prediction is +1 is wTx+b >= 1-epsilon and -1 if
wTx+b =< 1-epsilon, C is regularion param.
9. To use kernel, we can replace x with f(x)  and have wTf(x)+b here f is kernel function.
10. SGD can be using to train the model.
11. To regulate RBF(1/2sigma^2 * (x-x')), we need to tune sigma^2 
12. Another way to formulate is the take a dual of original optimization formulation after using langrange to transform constraint. (dont know much detail)
13. Advantages:
  - Can handle non-linear data through kernel trick
  - handle multi-co-linear data points
14. Disadvantages:
  - computationally expensive for large amount of data
  - can overfit is data is less than features.
  -  prediction is less interpretable as prediction is not interms of probabilty but one can take the score from linear model and convert into probability
Decision Tree:
1. Rule based system where given a feature and its values based on equality/inquality rules the algorithm splits the dataset. one can think is splitting as a creation of
two nodes (childred) in a tree for the parent node representative of the feature in question.
2. The leaf not indicates class or numeric number dependending on classifiction or regression problem.
3. Main challenge is to know at each stage which feature to be used for splitting.
4. Intuition is to find the most discreminative feature as each stage to split the dataset and one way to find that is through information gain measure. Information 
gain is a measure of entropy where higher entropy indicates more ambiguity in the class distribution less discrinative and lower entry low ambiguity higher discrimination
5. Information gain of feature a = entropy(S)-entropy(S|a), we want a with maximum information gain from the current state of the dataset to the splitting version.
7. tree depth is parameter used to regularize the tree
7. Advantages:
  - very interpretable, easy to explain a prediction.
  - easily adapt categorical and numerical feature.
  - low effort on data preprocessing.
8. DisAdvantages:
  - can easily overfit. Backward node prunning may help.
  - changes in training data cause entire tree recreation.
  - 
Random Forest:
1. This is collection of small depth decision trees.
2. Random forest address the overfitting issue of a single deep decision tree.
3. Random forest is an ensemble model trained through bagging.
4. At each step it samples K instances with replacement and build a decision tree.
5. One additional step it does is to also sample a set of features that it uses to build the trees. This help not make the tree correlated.
6. Random forest kind of overfits each tree but different feature set ensures overfitting happend in different direction and aggration of all these tree cancel out each
others overfitting.
7. For classification, it takes majority voting and average for regression.
8. number of estimators/trees and depth of each tree params can be use to regularize.
Advantages:
 - does not overfit
 - interpretable
 - handle missing data
Disadvantages:
  - longer training time
  
Gradient Boosted model:
1. another kind of ensemble model based on boosting.
2. The main idea is that, at every step we want to train a weak learner and in the following step only focus on data points where weak learner is not performing well.
3. Such aggration(addition) of weak learners made up an effective one. f_new = f_old+learning_rate*f_new
4. given y = f(x) is the model, at stage 0 we will train a basic weak learner (always output average of the class label or a very shallow tree) and get y^ (prediction)
now, record error y-y^ and replace target to y-y^ and try to fit another model f on (y-y^), Keep on doing this until there is no change is the error or number of iterations
expires.
5. gradient boosted model can be used for ranking, where given a ranking function f, prediction pairwise prediction y^(i>j) can be derived from a sigmoid 1/1+e(f(xi)-f(xj))
6. we can logloss -ylog(y^)-(1-y)log(1-y^) as cost function. (RankNet)
7. LambdaRank include change (delta) in NDCG when i and j are swapped in the gradient computation of the above log loss cost function.
8.Advantages:
  - Lots of flexibility - can optimize on different loss functions and provides several hyper parameter tuning options that make the function fit very flexible.
  - No data pre-processing required - often works great with categorical and numerical values as is.
  - Handles missing data - imputation not required.
  
9. Disadvantages:
  - Gradient Boosting Models will continue improving to minimize all errors. This can overemphasize outliers and cause overfitting.
  - Computationally expensive - often require many trees (>1000) which can be time and memory exhaustive.
  - The high flexibility results in many parameters that interact and influence heavily the behavior of the approach (number of iterations, tree depth, regularization parameters, etc.). This requires a large grid search during tuning.
  - Less interpretative in nature, although this is easily addressed with various tools.
  
Evaluation:
Classification:
  - Precision: ratio of correct out of all predicted
  - Recall: ratio of correct prediction out of all correct in the set
  - f1: hermonic mean between precision and recall
  - AUC: area under ROC curve measure for different threshold and plotted TPR and FPR.
    - when threshold is zero, both TPR and FPR is zero, indicating bottom left corner
    - when threshold is 1, both TPR and FPR is 1, indicating top right corner
  -PR curve - helps to determine what threshold to use for nominating a prediction as positive.
Regression:
  - R-Square: measure how good the prediction is compared to mean of the target variable.
  - Root mean square error: root of the mean square error (stable than MSE as MSE can explore in case of an outlire.)
Ranking:
  Mean Reciprocal rank: measure what is the rank of first relevant element. measured by mean(1/rank of first relevant element for each data query)
  Precision@K: what fraction of items withing top k is relevant. 
    - does not consider order among the items in the list
  Mean Precision: computed precision @1..K and average.
  Average Mean Precision: Average of mean precision accross queries/users
  CG: cumulative sum of relevance score for each element in the rank list
    - does not penalize of showing not relevant item on top position.
  DCG: 2^(rel_i)/log(i+1) for all ith item in the rank list.
    - hard to interprete and not comparable between users/queries.
  IDCG: DCG for idean rannking
  NDCG: DCG/IDCG: between 0 to 1
    - has problem handling when we dont have complete set of relevant score for the entire ranked list, challeng is how to fill those slots.
    -
Overfitting:

1. Detection of overfitting is possible from learning curve, that plots training error and validation/testing error.
2. if training error is low and testing error is high it overfitting.
3. overfitting can also reffer to the high variance low bias case.
4. To resolve overfitting one can:
  - regularize the model by adding penalty term in the cost function.
  - Add more data
  - reduce feature
  - lower down model's complexity.
  
Underfitting:
1. Detection of underfitting is possible from learning curve, that plots training error and validation/testing error.
2. if training error is high and testing/validation error is high then we can say model is suffering from underfitting.
3. underfitting is high bias low variation situation
4. to resolve underfitting one can:
  - increase model's complexity as adding more data will not help for degrade the situation.
  - add more features.
  
Regularization:
1. Regularization is the tool to address overfitting of the model.
2. There are several ways to enforce regularization and most trivial way is to add penalty term on the model's parameter in the cost function. There are several kinds 
of these penalty term, Ridge (l2) lasso (l1) and elastic (l1 and l2)
3. for tree models, by tuning depth of the tree, number of trees in the forest one can regularize.
4. Data augmentation also has regularization effects.
5. In deep learning, along with l2 regularion, dropout (randomly inactive nodes in the hidden layer), batch normalization (normalizing hidden layer output of 
layer i by 0 mean 1 std before passing to layer i+1) has regularization effect.

Loss functions:
1. log loss: -y*log(y^)-(1-y)*log(1-y^) for binary classification
2. Cross entropy loss: -log(p) p is the prpbability
3. hinge loss: SVM's hinge loss max(0, 1- y*y^)
   - there are many variations of hinge loss given a problem:
       - contrastive loss: given a pair (x1,x2) and label y indicating if x1 an x2 are relevant or not. constructive loss which is y*dist(x1,x2)+(1-y)*max(0,m-dist(x1,x2)). here m is the margin which is the max contribution to the loss when model makes mistake of learning distance between irrlevant item x1 and x2 to 0 i.e. very relevant. 
       - In other cases when relevant are detected as relevant (zero distance) and irrelevant are detected as irrelevant (large distance higher than m) the contribution of those instance to the loss function is 0.
       
4. Triplet loss: Triplet loss is another version of contrastive loss that works on a tuple of (x1,x2,x2) where x2 is relevant to x1 and x3 is irrelevant to x1.
   - loss = max(0, m+dist(x1,x2)-dist(x1,x3))
   - Easy case: dist(x1,x3) > m+dist(x1,x2) makes that training instance to contribute zero in the loss
   - Hard case: dist(x1,x3) < dist(x1,x2), this makes that training instance to contribute > m in the loss
   - Semi hard: m < dist(x1,x3) > dist(x1,x2) this makes that training instance to contribute < m in the loss
   - getting training instance of this format is hard
   - An important decision of a training with Triplet Ranking Loss is negatives selection or triplet mining. 
       - First strategies used offline triplet mining, which means that triplets are defined at the beginning of the training,
       - online triplet mining, meaning that triplets are defined for every batch during the training
Neutral Net:
1. Feed forward net: linera conbination of many linear conbination.
2. Forward propagation from layer 0 to output layer 
3. backprod: from loss using chain rule for partial derivation update parameters in each layer using gradient descent.
4. Non-linearity: to handle non-linear data, activation functions are introduced after each linear (wTx+b) computations on each hidden node.

Recurrent Neural Net:
1. RNN is a spacial kind of NN that handle cyclic operation meaning, output of a hiddne node at time stamp t-1 is using as an input in node at time t. Such recusive nature coined the name recurrent.
2. Such NN are perfect to model sequences.
3. RNN's can be bidirectional and multilayer.
4. h^t = g(wTx^t+ wTh^t-1 + b^t-1) here g is the activation functions and y = g(wTh^t+b) is the prediction using hidden layer h at time t.
5. backproagation in RNN is called back prod through time.
Advantages:
   - model sequence
   - shared parameter 
   - model size does not increase with larger sequence.
Disadvantages:
   - slow to train.
   - unable to capture sequential relation long time back.
   - Gradient can become very small as well as large during back prop
   
Gradient explosion:
1. In RNN, since parameters are shared and due to gradient multiplication, if gradient is larger and 1 then over time gradiant can explore and SGD start ossilationg due to large updates of the model.
  - clipping gradient is one way to handling explosive gradient.
Gradient vanishes:
1. This is the opposite situation of explosion and this cause SGD to very slow.
  - gated RNNs i.e LSTM, GRU developed to addess this situation where one can control whether to pass information from time t-1 to t. this cause braking the multiplication cycle.
  - changing activation functions is another way to handling this i.e sigmoid and tanh may cause gradiant vanish due to the output range of this function. Relu max(0,x) help in this case.
  
Batch normalization:
1. Batch normalization is a technique to handle data covariates shift from layer to layer.
2. Batch normalization does nomalization of hidden layer at t-1 using mean-0 std-1 before passing to layer t. 
3. This will help to ensure, hidden layers are receiving inputs that are following a same distribution (mean-0, std-1). 
4. Batch normalization cause faster convergence.
5. For inference time batch normalization, we can maintain exponential moving average of mean and std's of each batch and provide that during inference time.

Mini batch gradient descent:
1. version of gradient descent algorithm that does updates per batch 
2. Faster convergence.

Momentum:
1. Momentum keep tracks of exponetially moving average of gradients of each steps. vdW^t = beta*vdW+ (1-beta)dW and W = W- learning_rate*vdW.
   - helped to get out of local minima.
   - reduce ossication but maintain horizental movement.
RMSPorp
1. Version of Momentum having squared version of vdW
Adam
1. mix of momentum and RMSProp

Attention:
1. In RNN, to maintain longer dependency a context vector c is concatenated with the decoder hidden layer input at time t. 
2. This context vector c is generated using the attention model that holds the information of how much importance/weight should be given at the input hidden layer h_t while generated outout y_t in the decoder.
3. these weights are learned through a feedforward network using encoder and decoder's hidden using at time t-1. 
4. Weights are the softmax normalized of scores outout by the attention network also called alighment score.
5. Such attention is called global attention. from decoder to encoder.
6. Such attention can be additive (how encoder and decoder from attention network aggragate to product alignment score) (Bahdanau Attention) and multiplicative/dot/concatenated (luong attention)

Activation functions:
1. Sigmoid: sigmoid function map a real valued number between 0 and 1.
  - can cause neural network to get stuck during training due if the sigmoid repetably product number close to zero which is turn cause very slow movement in SGD
2. tanh: range -1 and 1
3. Relu: max (0, x)
  - all negative values become zero causing model not to fit the data properly
4. leaky relu: max(ax, x) where a==0.01
  - able to handle negative value
  
Two tower:
1. Siamese network where each tower is exactly the same i.e. both can be CNN followed by a fc.
2. combined with some similarity metric i.e. cosine simillarity, eucledian/manhattan distance.
3. Loss used either contrastive or triplet.
4. heavyly used in 
  - semantic search wher tower one is for query and tower two is for item.
  - recommendation, toweer one is for user and tower two is for item.
5. after training learned item embedding is indexed using optimized index solution i.e. faiise
6. during inference, query/user two generates the embedding and approximate KNN provides k most relevant items for search or recommendations.
7. in both the tower, other side information can be included.

Deep and wide:
1. In deep and wide network, deep part encode the semantice information either for query or user and wide part can handle tradition features and cross features. i.e. where item is from brand b and category c.
2. deep part can be any NN architecture and wide part is an MLP, finally these two concatenated and then through FC to the output/prediction node. 
3. cross entropy loss

Transformer:
1. Transformer is a attention network that can allow self attention i.e. which processing node at time t , it can focus/have weights on previous t-1 nodes.
2. Transformer has three concept 1) query 2) key and 3)value.
3. query is node at time stamp t
4. key are the hidden layers, from h0 to h_t-1.
5. once there is a key to the query, outout associated to the hidden unit to provided.
6. Transformer allow to have multiple attention head 
7. this attention is called dot-product attention as final z = softmax(queryDOTkey)value

BERT:
1. Bidirectional encoder trasnformer model.
2. positional encoding allow parallel processing of input states.
3. during training solve masked language model and next sentence prediction problem.
4. pretrain on text (unsuper vised) to generate language model.
5. can be fine tuned for a specific task

Subword Tokenization:
1. byte pair encoding: based on frequency, starts with character and every step merge most frequent n-grams. i.e. stage 2 will merge most frequence bigrams and stage 3 3-grams and so on, until target size of vocab.
2. word piece: same as byte pair but use likelihood not frequency.

Recommender system:
1. user-centric: model user's using a set of feature/parameters and solve a regression problem to predict rating of an item that has these features as well.
2. item-item centric: model items using a set of feature/parameters and solve a regression problem to predict rating of an item that has these features as well.
3. collaborative filtering: recommend one user from the understanding of another user that are similar to the input user.
4. Alternative least squares combines 1 and 2 and solve togather.
5. Matrix factorization if user-rating matrix.
6. Factor R (rating matrix) to U and V where U(user X k features) and V (items X k features)
7. dot product of one row in user matrix and one column of item matrix is the rating.
8. training through SGD using squared loss (R- UV^t)^2 while randomly initialize U and V

AB Test:
1. unpaired t test.
Mistakes not to make at AB Test:
1. Having many variations if bad idea as it will show down the test and can also impose risk on invalidating outcomes.
  - many variations mean longer running time and more resources.
  - longer running test have the risk for cookie deletion i.e sample polution. In that longer running time, people will have deleted their cookies and may enter a different variation than the one they were originally in.
  - too many variations increase the number of false positives.
  - this equation 1- (1-a)^m here (a is the significance level and m is the number of variations run) measure the amount of false positive possible for many variations. This is known as multiple comparison problem.
  - Bonferroni correction is the way to handle this, as per this each test should have significance level a/m.
2. changing test status i.e. assignment of traffic in mid test.
  - this will skew the sample assignment.
  - only new visitor after the time of the change will get impacted. Previous visitor will still follow old traffic assginment rule unless they delete their cookie.
3. segment wise post analysis of data should be done carefully.
   - even though the overall test has reached to enough visitor but sample size may still be not enough at segment level.
   - Also comparing different segments can raise multiple comparison problem.
   - its better to run targetted test on each segment than post split.
   - if thats not possible, make sure the data is segmented properly and have enough samples.

Human Annotation:
1. Inter-rater agreement reliability measures the extent to which independent raters assess a task and produce the same answer. 
One of the most widely used statistics to compute agreement is Cohen’s kappa (k), a chance-adjust measure of agreement between two raters. 
A generalization for n raters is Fleiss’ kappa
